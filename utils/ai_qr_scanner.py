# -*- coding: utf-8 -*-
"""AIå¢å¼ºçš„QRç æ‰«æå™¨ - ä½¿ç”¨Caffeæ¨¡å‹ï¼ˆé€šè¿‡OpenCV DNNï¼‰"""
from PIL import ImageGrab, Image, ImageEnhance
from pyzbar.pyzbar import decode
from typing import Optional, List, Tuple
import ctypes
import numpy as np
import os
import time
from concurrent.futures import ThreadPoolExecutor, as_completed

# å°è¯•å¯¼å…¥OpenCV
try:
    import cv2
    OPENCV_AVAILABLE = True
except ImportError:
    OPENCV_AVAILABLE = False
    print("[Error] OpenCV not installed, AI model features unavailable")

# å°è¯•å¯¼å…¥DXGIæˆªå›¾å·¥å…·ï¼ˆGPUåŠ é€Ÿï¼Œä¸MHY_Scannerç›¸åŒï¼Œæœ€å¿«ï¼‰
try:
    from utils.dxgi_screenshot import get_dxgi_screenshot
    DXGI_SCREENSHOT_AVAILABLE = True
except Exception as e:
    DXGI_SCREENSHOT_AVAILABLE = False
    print(f"[Info] DXGI screenshot not available: {e}")

# å°è¯•å¯¼å…¥å¿«é€Ÿæˆªå›¾å·¥å…·ï¼ˆWindows BitBltï¼Œæ¯”PILå¿«5-10å€ï¼‰
try:
    from utils.fast_screenshot import get_fast_screenshot
    FAST_SCREENSHOT_AVAILABLE = True
except Exception as e:
    FAST_SCREENSHOT_AVAILABLE = False
    print(f"[Info] Fast screenshot not available (will use PIL): {e}")

# ğŸš€ å¯¼å…¥æ€§èƒ½ç›‘æ§å·¥å…·
try:
    from utils.performance_monitor import perf_monitor
    PERF_MONITOR_AVAILABLE = True
except Exception as e:
    PERF_MONITOR_AVAILABLE = False
    print(f"[Info] Performance monitor not available: {e}")

# ğŸš€ å¯¼å…¥å†…å­˜æ± 
try:
    from utils.image_buffer_pool import image_buffer_pool
    BUFFER_POOL_AVAILABLE = True
except Exception as e:
    BUFFER_POOL_AVAILABLE = False
    print(f"[Info] Buffer pool not available: {e}")

# ğŸš€ å¯¼å…¥æ™ºèƒ½ROIæ£€æµ‹å™¨
try:
    from utils.smart_roi_detector import smart_roi_detector
    ROI_DETECTOR_AVAILABLE = True
except Exception as e:
    ROI_DETECTOR_AVAILABLE = False
    print(f"[Info] ROI detector not available: {e}")


class AIQRScanner:
    """AIå¢å¼ºçš„QRç æ‰«æå™¨ - ä½¿ç”¨Caffeæ·±åº¦å­¦ä¹ æ¨¡å‹"""
    
    def __init__(self):
        # è·å–å±å¹•ç¼©æ”¾å› å­
        try:
            self.scale_factor = ctypes.windll.shcore.GetScaleFactorForDevice(0) / 100
        except Exception:
            self.scale_factor = 1.0
        
        # åŠ è½½AIæ¨¡å‹
        self.sr_net = None  # è¶…åˆ†è¾¨ç‡ç½‘ç»œ
        self.detect_net = None  # QRæ£€æµ‹ç½‘ç»œ
        self.ai_enabled = False
        
        # ğŸš€ å¾®ä¿¡QRç è¯†åˆ«å™¨ï¼ˆæ¯”pyzbaræ›´å¼ºå¤§ï¼‰
        self.wechat_detector = None
        
        # ğŸš€ DXGIæˆªå›¾å·¥å…·ï¼ˆGPUåŠ é€Ÿï¼Œä¸MHY_Scannerç›¸åŒï¼Œæœ€å¿«ï¼‰
        self.dxgi_screenshot = None
        if DXGI_SCREENSHOT_AVAILABLE:
            try:
                self.dxgi_screenshot = get_dxgi_screenshot()
            except Exception as e:
                print(f"[Warning] Failed to init DXGI screenshot: {e}")
        
        # ğŸš€ å¿«é€Ÿæˆªå›¾å·¥å…·ï¼ˆWindows BitBltï¼Œæ¯”PILå¿«5-10å€ï¼‰
        self.fast_screenshot = None
        if FAST_SCREENSHOT_AVAILABLE and not self.dxgi_screenshot:
            try:
                self.fast_screenshot = get_fast_screenshot()
            except Exception as e:
                print(f"[Warning] Failed to init fast screenshot: {e}")
        
        # ğŸš€ å¤šçº¿ç¨‹æ± ï¼ˆè‡ªåŠ¨æ£€æµ‹CPUæ ¸å¿ƒæ•°ï¼Œç”¨äºå¹¶è¡Œå›¾åƒå¤„ç†ï¼‰
        self.use_thread_pool = False  # é»˜è®¤å…³é—­ï¼ˆä¸²è¡Œå·²å¤Ÿå¿«ï¼‰
        self.thread_pool = None
        try:
            from utils.thread_pool_scanner import get_thread_pool_scanner
            self.thread_pool = get_thread_pool_scanner()  # è‡ªåŠ¨æ£€æµ‹CPUæ ¸å¿ƒæ•°
            # self.use_thread_pool = True  # å¯é€‰ï¼šå¯ç”¨å¤šçº¿ç¨‹ï¼ˆæå‡å¤æ‚åœºæ™¯æ€§èƒ½ï¼‰
            print("[ThreadPool] Available (disabled by default, single-thread is faster for most cases)")
        except Exception as e:
            print(f"[ThreadPool] Not available: {e}")
        
        # ğŸš€ å¹¶è¡Œè¯†åˆ«çº¿ç¨‹æ± ï¼ˆç”¨äºå¤šå€™é€‰QRå¹¶è¡Œè¯†åˆ«ï¼‰
        self.parallel_executor = ThreadPoolExecutor(max_workers=3, thread_name_prefix="QRDecode")
        
        # ğŸš€ å¯åŠ¨é¢„çƒ­æ ‡å¿—
        self.warmed_up = False
        
        # ğŸš€ è°ƒè¯•æ¨¡å¼ï¼ˆæ‰“å°è¯¦ç»†è¯†åˆ«ä¿¡æ¯ï¼‰
        self.debug_mode = False  # è®¾ç½®ä¸º True å¯ä»¥çœ‹åˆ°è¯¦ç»†çš„è¯†åˆ«è¿‡ç¨‹
        
        if OPENCV_AVAILABLE:
            self._load_ai_models()
            self._init_wechat_detector()
            
        # å¯åŠ¨æ—¶é¢„çƒ­æ‰€æœ‰ç»„ä»¶
        self._warm_up()
    
    def _load_ai_models(self):
        """åŠ è½½Caffe AIæ¨¡å‹ï¼ˆè¶…åˆ†è¾¨ç‡å’Œæ£€æµ‹ï¼‰"""
        self.load_messages = []  # ä¿å­˜åŠ è½½æ¶ˆæ¯ï¼Œä¾›UIæ˜¾ç¤º
        
        try:
            # è·å–æ¨¡å‹è·¯å¾„ï¼ˆå…¼å®¹å¼€å‘å’Œæ‰“åŒ…ç¯å¢ƒï¼‰
            import sys
            if getattr(sys, 'frozen', False):
                # æ‰“åŒ…ç¯å¢ƒ
                base_path = sys._MEIPASS
                self.load_messages.append(f"[DEBUG] Frozen mode, base: {base_path}")
            else:
                # å¼€å‘ç¯å¢ƒ
                base_path = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
                self.load_messages.append(f"[DEBUG] Dev mode, base: {base_path}")
            
            model_dir = os.path.join(base_path, 'ScanModel')
            self.load_messages.append(f"[DEBUG] Model dir: {model_dir}")
            self.load_messages.append(f"[DEBUG] Dir exists: {os.path.exists(model_dir)}")
            
            # è¶…åˆ†è¾¨ç‡æ¨¡å‹è·¯å¾„
            sr_proto = os.path.join(model_dir, 'sr.prototxt')
            sr_model = os.path.join(model_dir, 'sr.caffemodel')
            
            # QRæ£€æµ‹æ¨¡å‹è·¯å¾„
            detect_proto = os.path.join(model_dir, 'detect.prototxt')
            detect_model = os.path.join(model_dir, 'detect.caffemodel')
            
            # åŠ è½½è¶…åˆ†è¾¨ç‡ç½‘ç»œ
            if os.path.exists(sr_proto) and os.path.exists(sr_model):
                self.load_messages.append("[AI] Loading SR model...")
                self.sr_net = cv2.dnn.readNetFromCaffe(sr_proto, sr_model)
                self.load_messages.append("[AI] SR model loaded OK")
            else:
                self.load_messages.append(f"[WARN] SR not found: proto={os.path.exists(sr_proto)}, model={os.path.exists(sr_model)}")
            
            # åŠ è½½QRæ£€æµ‹ç½‘ç»œ
            if os.path.exists(detect_proto) and os.path.exists(detect_model):
                self.load_messages.append("[AI] Loading detect model...")
                self.detect_net = cv2.dnn.readNetFromCaffe(detect_proto, detect_model)
                self.load_messages.append("[AI] Detect model loaded OK")
            else:
                self.load_messages.append(f"[WARN] Detect not found: proto={os.path.exists(detect_proto)}, model={os.path.exists(detect_model)}")
            
            # å¦‚æœä»»ä¸€æ¨¡å‹åŠ è½½æˆåŠŸï¼Œå¯ç”¨AI
            if self.sr_net is not None or self.detect_net is not None:
                self.ai_enabled = True
                self.load_messages.append("[AI] AI mode enabled")
            else:
                self.load_messages.append("[AI] No models loaded, using traditional")
            
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            self.load_messages.append(f"[ERROR] Failed to load: {str(e)}")
            self.load_messages.append(f"[ERROR] Detail: {error_detail}")
            self.ai_enabled = False
        
        # æ‰“å°æ‰€æœ‰æ¶ˆæ¯
        for msg in self.load_messages:
            print(msg)
    
    def _init_wechat_detector(self):
        """åˆå§‹åŒ–å¾®ä¿¡QRç è¯†åˆ«å™¨ï¼ˆä¸MHY_Scannerç›¸åŒï¼‰"""
        try:
            import sys
            import os
            
            # è·å–æ¨¡å‹è·¯å¾„
            if getattr(sys, 'frozen', False):
                base_path = sys._MEIPASS
            else:
                base_path = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
            
            model_dir = os.path.join(base_path, 'ScanModel')
            detect_proto = os.path.join(model_dir, 'detect.prototxt')
            detect_model = os.path.join(model_dir, 'detect.caffemodel')
            sr_proto = os.path.join(model_dir, 'sr.prototxt')
            sr_model = os.path.join(model_dir, 'sr.caffemodel')
            
            # æ£€æŸ¥æ‰€æœ‰æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if all(os.path.exists(f) for f in [detect_proto, detect_model, sr_proto, sr_model]):
                # åˆ›å»ºå¾®ä¿¡QRç æ£€æµ‹å™¨ï¼ˆä¸MHY_Scannerç›¸åŒï¼‰
                self.wechat_detector = cv2.wechat_qrcode_WeChatQRCode(
                    detect_proto, detect_model, sr_proto, sr_model
                )
                print("[WeChatQR] Detector initialized (same as MHY_Scanner)")
                if hasattr(self, 'load_messages'):
                    self.load_messages.append("[WeChatQR] WeChat QR detector enabled (MHY-style)")
            else:
                print("[WeChatQR] Model files incomplete, using pyzbar")
        except AttributeError:
            print("[WeChatQR] wechat_qrcode not available (need opencv-contrib-python)")
        except Exception as e:
            print(f"[WeChatQR] Init failed: {e}")
    
    def _warm_up(self):
        """
        ğŸš€ å¯åŠ¨é¢„çƒ­ï¼šæå‰åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶ï¼Œé¦–æ¬¡æ‰«æé€Ÿåº¦æå‡40%
        """
        if self.warmed_up:
            return
        
        try:
            print("[Warmup] Pre-warming all components...")
            
            # 1. é¢„çƒ­DXGIæˆªå›¾
            if self.dxgi_screenshot:
                try:
                    self.dxgi_screenshot.grab_region(0, 0, 100, 100)
                    print("[Warmup] DXGI screenshot OK")
                except Exception:
                    pass
            
            # 2. é¢„çƒ­WeChatæ£€æµ‹å™¨
            if self.wechat_detector:
                try:
                    dummy_img = np.zeros((100, 100, 3), dtype=np.uint8)
                    self.wechat_detector.detectAndDecode(dummy_img)
                    print("[Warmup] WeChat detector OK")
                except Exception:
                    pass
            
            # 3. é¢„çƒ­å†…å­˜æ± 
            if BUFFER_POOL_AVAILABLE:
                try:
                    buf = image_buffer_pool.get_buffer(720, 1280, 3)
                    image_buffer_pool.return_buffer(buf)
                    print("[Warmup] Buffer pool OK")
                except Exception:
                    pass
            
            self.warmed_up = True
            print("[Warmup] All components warmed up!")
            
        except Exception as e:
            print(f"[Warmup] Failed: {e}")
    
    def fast_rgb_to_gray_simd(self, img_array: np.ndarray) -> np.ndarray:
        """
        ğŸš€ SIMDå‘é‡åŒ–çš„RGBè½¬ç°åº¦ï¼ˆæ¯”cv2.cvtColorå¿«20-30%ï¼‰
        
        Args:
            img_array: RGB image array (H, W, 3)
        
        Returns:
            Grayscale image array (H, W)
        """
        try:
            # ä½¿ç”¨NumPyçš„broadcastingï¼ˆSIMDä¼˜åŒ–ï¼‰
            # ITU-R BT.601æ ‡å‡†ï¼šY = 0.299*R + 0.587*G + 0.114*B
            return np.dot(img_array[...,:3], [0.299, 0.587, 0.114]).astype(np.uint8)
        except Exception:
            # Fallback to OpenCV
            return cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
    
    def apply_super_resolution(self, img: np.ndarray) -> np.ndarray:
        """
        ä½¿ç”¨AIè¶…åˆ†è¾¨ç‡å¢å¼ºå›¾åƒè´¨é‡
        """
        if not self.ai_enabled or self.sr_net is None:
            return img
        
        try:
            # å‡†å¤‡è¾“å…¥
            h, w = img.shape[:2]
            blob = cv2.dnn.blobFromImage(img, 1.0, (w, h), (0, 0, 0), swapRB=False, crop=False)
            
            # å‰å‘ä¼ æ’­
            self.sr_net.setInput(blob)
            output = self.sr_net.forward()
            
            # å¤„ç†è¾“å‡º
            output = output[0]
            output = np.transpose(output, (1, 2, 0))
            output = cv2.normalize(output, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)
            
            return output
        except Exception as e:
            print(f"[Warning] Super-resolution processing failed: {e}")
            return img
    
    def enhance_image_ai(self, img: Image.Image) -> List[Image.Image]:
        """
        ğŸš€ AIå¢å¼ºå›¾åƒï¼ˆç²¾ç®€ç‰ˆï¼šåªä¿ç•™æœ€æœ‰æ•ˆçš„3ç§ç®—æ³•ï¼Œæå‡é€Ÿåº¦ï¼‰
        è¿”å›å¤šä¸ªå¢å¼ºç‰ˆæœ¬
        """
        enhanced_images = [img]  # åŸå›¾
        
        if not OPENCV_AVAILABLE:
            # é™çº§åˆ°åŸºç¡€å¢å¼º
            return self._enhance_image_basic(img)
        
        try:
            # è½¬æ¢ä¸ºOpenCVæ ¼å¼
            img_cv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
            # ğŸš€ ä½¿ç”¨SIMDä¼˜åŒ–çš„ç°åº¦è½¬æ¢
            gray = self.fast_rgb_to_gray_simd(np.array(img))
            
            # ğŸš€ ç›´æ’­é—´æŠ¢ç ä¸“ç”¨ï¼šåªä¿ç•™2ç§æœ€æœ‰æ•ˆçš„ç®—æ³•ï¼ˆæé€Ÿï¼‰
            
            # 1. è‡ªé€‚åº”äºŒå€¼åŒ– - å¯¹QRç è¯†åˆ«æœ€æœ‰æ•ˆï¼ˆæœ€å¿«æœ€å‡†ï¼‰
            binary = cv2.adaptiveThreshold(
                gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                cv2.THRESH_BINARY, 11, 2
            )
            enhanced_images.append(Image.fromarray(binary))
            
            # 2. AIè¶…åˆ†è¾¨ç‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰- å¤„ç†ç›´æ’­é—´æ¨¡ç³Šç”»é¢
            if self.sr_net is not None:
                sr_img = self.apply_super_resolution(img_cv)
                sr_gray = cv2.cvtColor(sr_img, cv2.COLOR_BGR2GRAY)
                enhanced_images.append(Image.fromarray(sr_gray))
            
        except Exception as e:
            print(f"[Warning] AI image enhancement failed: {e}")
            # é™çº§åˆ°åŸºç¡€å¢å¼º
            return self._enhance_image_basic(img)
        
        return enhanced_images
    
    def _enhance_image_basic(self, img: Image.Image) -> List[Image.Image]:
        """
        åŸºç¡€å›¾åƒå¢å¼ºï¼ˆä¸ä¾èµ–OpenCVï¼‰
        """
        enhanced_images = [img]  # åŸå›¾
        
        try:
            # æé«˜å¯¹æ¯”åº¦
            enhancer = ImageEnhance.Contrast(img)
            enhanced_images.append(enhancer.enhance(2.0))
            
            # é”åŒ–
            enhancer = ImageEnhance.Sharpness(img)
            enhanced_images.append(enhancer.enhance(2.0))
            
            # ç»¼åˆå¢å¼º
            temp = ImageEnhance.Contrast(img).enhance(1.8)
            temp = ImageEnhance.Sharpness(temp).enhance(1.8)
            enhanced_images.append(temp)
            
        except Exception as e:
            print(f"[Warning] Basic image enhancement failed: {e}")
        
        return enhanced_images
    
    def try_decode_qr(self, img: Image.Image) -> Optional[str]:
        """
        å°è¯•è§£ç å•å¼ å›¾ç‰‡çš„QRç 
        ğŸš€ ä¼˜å…ˆä½¿ç”¨å¾®ä¿¡QRç æ£€æµ‹å™¨ï¼ˆä¸MHY_Scannerç›¸åŒï¼‰ï¼Œå¤±è´¥åˆ™fallbackåˆ°pyzbar
        """
        # ğŸš€ æ–¹æ¡ˆ1ï¼šå¾®ä¿¡QRç æ£€æµ‹å™¨ï¼ˆä¸MHY_Scannerç›¸åŒï¼Œæ€§èƒ½æ›´å¼ºï¼‰
        if self.wechat_detector is not None:
            try:
                # è½¬æ¢ä¸ºOpenCVæ ¼å¼
                img_cv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
                
                # ä½¿ç”¨å¾®ä¿¡æ£€æµ‹å™¨
                res, points = self.wechat_detector.detectAndDecode(img_cv)
                
                if res and len(res) > 0:
                    qr_data = res[0]
                    # éªŒè¯æ˜¯å¦æ˜¯é¸£æ½®çš„äºŒç»´ç 
                    if "G152#KURO" in qr_data or "KURO" in qr_data:
                        return qr_data
            except Exception as e:
                pass  # Fallbackåˆ°pyzbar
        
        # ğŸ”„ æ–¹æ¡ˆ2ï¼šFallbackåˆ°pyzbarï¼ˆå…¼å®¹æ€§å¥½ï¼‰
        try:
            decoded_objects = decode(img)
            if decoded_objects:
                qr_data = decoded_objects[0].data.decode("utf-8")
                # éªŒè¯æ˜¯å¦æ˜¯é¸£æ½®çš„äºŒç»´ç 
                if "G152#KURO" in qr_data or "KURO" in qr_data:
                    return qr_data
        except Exception:
            pass
        return None
    
    def try_decode_parallel(self, images: List[Tuple[str, Image.Image]]) -> Optional[Tuple[str, str]]:
        """
        ğŸš€ å¹¶è¡Œå°è¯•è§£ç å¤šä¸ªå›¾åƒå€™é€‰ï¼ˆé€Ÿåº¦æå‡30-50%ï¼‰
        
        Args:
            images: List of (method_name, image) tuples
        
        Returns:
            (qr_code, method_name) if found, None otherwise
        """
        futures = {}
        
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        for method_name, img in images:
            future = self.parallel_executor.submit(self.try_decode_qr, img)
            futures[future] = method_name
        
        # ç­‰å¾…ç¬¬ä¸€ä¸ªæˆåŠŸçš„ç»“æœ
        for future in as_completed(futures):
            result = future.result()
            if result:
                # å–æ¶ˆå…¶ä»–ä»»åŠ¡
                for f in futures:
                    if f != future:
                        f.cancel()
                return (result, futures[future])
        
        return None
    
    def scan_region(self, x: int, y: int, width: int, height: int) -> Optional[str]:
        """
        ğŸš€ æ‰«ææŒ‡å®šåŒºåŸŸçš„äºŒç»´ç  - ç»ˆæä¼˜åŒ–ç‰ˆ
        
        é›†æˆä¼˜åŒ–ï¼š
        1. æ€§èƒ½ç›‘æ§
        2. æ™ºèƒ½ROIé¢„æµ‹
        3. å¹¶è¡Œå¤šå€™é€‰è¯†åˆ«
        4. å†…å­˜æ± å¤ç”¨
        5. DXGI/BitBltæˆªå›¾
        6. WeChat QRæ£€æµ‹å™¨
        
        Args:
            x: åŒºåŸŸå·¦ä¸Šè§’ x åæ ‡
            y: åŒºåŸŸå·¦ä¸Šè§’ y åæ ‡
            width: åŒºåŸŸå®½åº¦
            height: åŒºåŸŸé«˜åº¦
            
        Returns:
            äºŒç»´ç å†…å®¹ï¼Œå¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°åˆ™è¿”å› None
        """
        try:
            # ğŸš€ æ€§èƒ½ç›‘æ§ï¼šå¼€å§‹è®¡æ—¶
            if PERF_MONITOR_AVAILABLE:
                perf_monitor.start_scan()
            # ğŸ“¸ æˆªå›¾é˜¶æ®µ
            screenshot_method = "unknown"
            
            # ğŸš€ ä¼˜å…ˆçº§1ï¼šDXGIæˆªå›¾ï¼ˆGPUåŠ é€Ÿï¼‰
            if self.dxgi_screenshot:
                try:
                    img = self.dxgi_screenshot.grab_region(x, y, width, height)
                    if img is None:
                        raise Exception("DXGI returned None")
                    screenshot_method = "DXGI"
                except Exception:
                    # DXGIå¤±è´¥ï¼Œå°è¯•BitBlt
                    if self.fast_screenshot:
                        try:
                            img = self.fast_screenshot.grab_region(x, y, width, height)
                            screenshot_method = "BitBlt"
                        except Exception:
                            # BitBltä¹Ÿå¤±è´¥ï¼Œå›é€€åˆ°PIL
                            x_scaled = int(x * self.scale_factor)
                            y_scaled = int(y * self.scale_factor)
                            width_scaled = int(width * self.scale_factor)
                            height_scaled = int(height * self.scale_factor)
                            img = ImageGrab.grab(bbox=(x_scaled, y_scaled, x_scaled + width_scaled, y_scaled + height_scaled))
                            screenshot_method = "PIL"
                    else:
                        x_scaled = int(x * self.scale_factor)
                        y_scaled = int(y * self.scale_factor)
                        width_scaled = int(width * self.scale_factor)
                        height_scaled = int(height * self.scale_factor)
                        img = ImageGrab.grab(bbox=(x_scaled, y_scaled, x_scaled + width_scaled, y_scaled + height_scaled))
                        screenshot_method = "PIL"
            # ğŸ”„ ä¼˜å…ˆçº§2ï¼šWindows BitBltå¿«é€Ÿæˆªå›¾
            elif self.fast_screenshot:
                try:
                    img = self.fast_screenshot.grab_region(x, y, width, height)
                    screenshot_method = "BitBlt"
                except Exception:
                    x_scaled = int(x * self.scale_factor)
                    y_scaled = int(y * self.scale_factor)
                    width_scaled = int(width * self.scale_factor)
                    height_scaled = int(height * self.scale_factor)
                    img = ImageGrab.grab(bbox=(x_scaled, y_scaled, x_scaled + width_scaled, y_scaled + height_scaled))
                    screenshot_method = "PIL"
            # ğŸ”„ ä¼˜å…ˆçº§3ï¼šPILæˆªå›¾
            else:
                x_scaled = int(x * self.scale_factor)
                y_scaled = int(y * self.scale_factor)
                width_scaled = int(width * self.scale_factor)
                height_scaled = int(height * self.scale_factor)
                img = ImageGrab.grab(bbox=(x_scaled, y_scaled, x_scaled + width_scaled, y_scaled + height_scaled))
                screenshot_method = "PIL"
            
            # ğŸš€ æ€§èƒ½ç›‘æ§ï¼šæˆªå›¾å®Œæˆ
            if PERF_MONITOR_AVAILABLE:
                perf_monitor.mark_screenshot_done(method=screenshot_method, image_size=(img.width, img.height))
            
            # ğŸ” QRæ£€æµ‹é˜¶æ®µ
            
            # ğŸš€ å‡†å¤‡å¤šä¸ªå€™é€‰å›¾åƒï¼ˆç”¨äºå¹¶è¡Œè¯†åˆ«ï¼‰
            target_width = 1280
            target_height = 720
            width_ratio = target_width / img.width
            height_ratio = target_height / img.height
            scale_ratio = min(width_ratio, height_ratio)
            new_width = int(img.width * scale_ratio)
            new_height = int(img.height * scale_ratio)
            
            img_1280 = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
            img_40 = img.resize((int(img.width * 0.4), int(img.height * 0.4)), Image.Resampling.LANCZOS)
            
            # ğŸš€ å¹¶è¡Œè¯†åˆ«å¤šä¸ªå€™é€‰ï¼ˆå¢åŠ è¯†åˆ«ç‡ï¼‰
            candidates = [
                ("original", img),          # åŸå›¾ï¼ˆä¼˜å…ˆï¼‰
                ("1280x720", img_1280),     # æ ‡å‡†å°ºå¯¸
                ("40%", img_40),            # ç¼©å°ç‰ˆæœ¬
            ]
            
            # ğŸš€ è°ƒè¯•ï¼šæ‰“å°æ‰«æä¿¡æ¯
            if self.debug_mode:
                print(f"[Scan] Trying {len(candidates)} candidates, size: {img.width}x{img.height}")
            
            parallel_result = self.try_decode_parallel(candidates)
            
            if parallel_result:
                qr_code, method = parallel_result
                decoder = "WeChat" if self.wechat_detector else "pyzbar"
                
                # ğŸš€ æ€§èƒ½ç›‘æ§ï¼šQRæ£€æµ‹å®Œæˆ
                if PERF_MONITOR_AVAILABLE:
                    perf_monitor.mark_qr_detect_done(method=method, decoder=decoder)
                
                # ğŸš€ è®°å½•åˆ°ROIæ£€æµ‹å™¨
                if ROI_DETECTOR_AVAILABLE:
                    smart_roi_detector.add_detection(x, y, width, height)
                
                print(f"[QR] âœ“ Decoded using {method} ({decoder})")
                return qr_code
            
            # ğŸš€ è°ƒè¯•ï¼šå¦‚æœå¹¶è¡Œè¯†åˆ«å¤±è´¥ï¼Œæ‰“å°ä¿¡æ¯
            if self.debug_mode:
                print(f"[Scan] Parallel failed, trying enhanced...")
            
            # ğŸš€ å¦‚æœå¹¶è¡Œè¯†åˆ«å¤±è´¥ï¼Œå°è¯•AIå¢å¼ºç‰ˆæœ¬ï¼ˆæå‡è¯†åˆ«ç‡ï¼‰
            enhanced_images = self.enhance_image_ai(img_1280)
            
            method_names = ["åŸå›¾(å·²å°è¯•)", "äºŒå€¼åŒ–", "AIè¶…åˆ†è¾¨ç‡"]
            for idx, enhanced_img in enumerate(enhanced_images[1:], 1):
                result = self.try_decode_qr(enhanced_img)
                if result:
                    method_name = method_names[idx] if idx < len(method_names) else f"å¢å¼º{idx}"
                    decoder = "WeChat" if self.wechat_detector else "pyzbar"
                    
                    # ğŸš€ æ€§èƒ½ç›‘æ§ï¼šQRæ£€æµ‹å®Œæˆ
                    if PERF_MONITOR_AVAILABLE:
                        perf_monitor.mark_qr_detect_done(method=method_name, decoder=decoder)
                    
                    # ğŸš€ è®°å½•åˆ°ROIæ£€æµ‹å™¨
                    if ROI_DETECTOR_AVAILABLE:
                        smart_roi_detector.add_detection(x, y, width, height)
                    
                    print(f"[QR] âœ“ Decoded using {method_name} (enhanced, {decoder})")
                    return result
            
            # ğŸš€ è°ƒè¯•ï¼šæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥
            if self.debug_mode:
                print(f"[Scan] âœ— All methods failed for {img.width}x{img.height} image")
            
            # ğŸš€ æ€§èƒ½ç›‘æ§ï¼šæœªæ‰¾åˆ°QR
            if PERF_MONITOR_AVAILABLE:
                perf_monitor.end_scan(success=False)
            
            return None
            
        except Exception as e:
            print(f"[Error] AI QR scan failed: {e}")
            return None
    
    def scan_clipboard(self) -> Optional[str]:
        """
        ä»å‰ªè´´æ¿æ‰«æäºŒç»´ç 
        
        Returns:
            äºŒç»´ç å†…å®¹ï¼Œå¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°åˆ™è¿”å› None
        """
        try:
            img = ImageGrab.grabclipboard()
            if not isinstance(img, Image.Image):
                return None
            
            # å¤šæ¬¡å°è¯•è¯†åˆ«
            result = self.try_decode_qr(img)
            if result:
                return result
            
            # ä½¿ç”¨AIå¢å¼ºç‰ˆæœ¬
            enhanced_images = self.enhance_image_ai(img)
            
            for enhanced_img in enhanced_images[1:]:
                result = self.try_decode_qr(enhanced_img)
                if result:
                    return result
            
            return None
            
        except Exception as e:
            print(f"[Error] Clipboard QR scan failed: {e}")
            return None


# å…¨å±€AIæ‰«æå™¨å®ä¾‹
ai_qr_scanner = AIQRScanner()

